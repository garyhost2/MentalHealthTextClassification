{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10759327,"sourceType":"datasetVersion","datasetId":6673921}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"text-align:center; font-size: 32px; color: #2c3e50;\">üèÜ 4th Place Solution üèÜ</h1>\n<h2 style=\"text-align:center; font-size: 24px; color: #34495e;\">GODS Hackathon</h2>\n<h3 style=\"text-align:center; font-size: 20px; color: #2980b9;\">NLP for Mental Health</h3>\n<p style=\"text-align:center; font-size: 18px; color: #555;\">\n   This notebook presents the <strong>4th place solution</strong> in the <strong>GODS Hackathon</strong>, where we applied <strong>Natural Language Processing (NLP)</strong> \n   to tackle challenges in <strong>mental health analysis and intervention</strong>.  \n</p>\n<hr style=\"border: 1px solid #ddd;\">\n<p style=\"text-align:center; font-size: 16px; color: #666;\">\n   üèÖ Ranked <strong>4th place</strong> among top AI & NLP solutions.<br>\n   üí° Utilized <strong>state-of-the-art language models</strong> to analyze mental health data.<br>\n  \n   .\n</p>","metadata":{"_uuid":"103fe762-83f2-4c2e-8b46-9b20772b17a7","_cell_guid":"58845fc3-0275-44cd-807f-3bc25c511ca6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    DebertaV2Tokenizer, DebertaV2Model,\n    RobertaTokenizer, RobertaModel,\n    AdamW, get_linear_schedule_with_warmup\n)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, f1_score\nfrom collections import Counter\nfrom tqdm import tqdm\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"24d27150-2401-46b7-9aff-1fcccaaab70d","_cell_guid":"8a082237-9cef-448b-b6e0-34a50787e5a9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-02-16T08:50:26.619561Z","iopub.execute_input":"2025-02-16T08:50:26.619861Z","iopub.status.idle":"2025-02-16T08:50:26.624362Z","shell.execute_reply.started":"2025-02-16T08:50:26.619841Z","shell.execute_reply":"2025-02-16T08:50:26.623529Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Configuration for all models","metadata":{}},{"cell_type":"code","source":"class Config:\n    models = {\n        'deberta': {\n            'name': 'microsoft/deberta-v3-base',\n            'batch_size': 8,\n            'lr': 3e-5,\n            'max_len': 512\n        },\n        'roberta-base': {\n            'name': 'roberta-base',\n            'batch_size': 8,\n            'lr': 2e-5,\n            'max_len': 512\n        },\n        'roberta-large': {\n            'name': 'roberta-large',\n            'batch_size': 4,\n            'lr': 1e-5,\n            'max_len': 512\n        }\n    }\n    epochs = 3\n    num_classes = 5\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    num_workers = os.cpu_count()\n    early_stopping_patience = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T08:50:27.543894Z","iopub.execute_input":"2025-02-16T08:50:27.544174Z","iopub.status.idle":"2025-02-16T08:50:27.622382Z","shell.execute_reply.started":"2025-02-16T08:50:27.544153Z","shell.execute_reply":"2025-02-16T08:50:27.621553Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Data Augmentation Class (remains unchanged)\nclass DataAugmentor:\n    def __init__(self, model_name=\"gpt2\"):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n        self.model.to(Config.device)\n\n    def generate_similar_text(self, text, num_variations=1, max_length=512):\n        \"\"\"Generate variations of the input text using the LLM.\"\"\"\n        max_input_length = 200  # Reserve space for generation\n        if len(text) > max_input_length:\n            text = text[:max_input_length]\n\n        prompt = f\"Generate a similar text to: {text}\\nSimilar text:\"\n\n        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(Config.device)\n        input_length = input_ids.shape[1]\n\n        outputs = self.model.generate(\n            input_ids,\n            max_new_tokens=100,  # Control the length of generated text\n            num_return_sequences=num_variations,\n            temperature=0.8,\n            top_p=0.9,\n            do_sample=True,\n            pad_token_id=self.tokenizer.eos_token_id,\n            no_repeat_ngram_size=3,  # Prevent repetitive text\n            length_penalty=1.0  # Encourage moderate length outputs\n        )\n\n        generated_texts = []\n        for output in outputs:\n            generated_text = self.tokenizer.decode(output[input_length:], skip_special_tokens=True).strip()\n            if generated_text:  # Only add non-empty generations\n                generated_texts.append(generated_text)\n\n        return generated_texts\n\ndef balance_dataset(df, augment_classes=[0, 4]):\n    \"\"\"Balance the dataset by augmenting the specified classes.\"\"\"\n    class_counts = df['label'].value_counts()\n    max_class_count = class_counts.max()\n\n    augmentor = DataAugmentor()\n    augmented_data = []\n\n    for cls in augment_classes:\n        class_samples = df[df['label'] == cls]\n        samples_needed = max_class_count - len(class_samples)\n\n        if samples_needed <= 0:\n            print(f\"Class {cls} doesn't need augmentation.\")\n            continue\n\n        print(f\"Generating {samples_needed} new samples for class {cls}...\")\n\n        for idx, row in tqdm(class_samples.iterrows(), total=len(class_samples), desc=f\"Augmenting class {cls}\"):\n            num_variations = samples_needed // len(class_samples) + 1\n            original_text = f\"{row['title']} {row['content']}\"\n\n            try:\n                generated_texts = augmentor.generate_similar_text(\n                    original_text,\n                    num_variations=min(num_variations, 5)  # Limit variations per sample\n                )\n\n                for text in generated_texts[:samples_needed]:\n                    split_point = min(len(text) // 4, 50)  # Use first quarter or 50 chars as title\n                    new_title = text[:split_point].strip()\n                    new_content = text[split_point:].strip()\n\n                    if new_title and new_content:  # Only add if both title and content exist\n                        augmented_data.append({\n                            'title': new_title,\n                            'content': new_content,\n                            'target': row['target'],\n                            'label': cls\n                        })\n\n                    samples_needed -= 1\n                    if samples_needed <= 0:\n                        break\n\n            except Exception as e:\n                print(f\"Error generating text for sample {idx} in class {cls}: {str(e)}\")\n                continue\n\n    print(f\"Successfully generated {len(augmented_data)} new samples\")\n    augmented_df = pd.DataFrame(augmented_data)\n    balanced_df = pd.concat([df, augmented_df], ignore_index=True)\n    return balanced_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T08:56:46.753592Z","iopub.execute_input":"2025-02-16T08:56:46.753912Z","iopub.status.idle":"2025-02-16T08:56:46.764715Z","shell.execute_reply.started":"2025-02-16T08:56:46.753886Z","shell.execute_reply":"2025-02-16T08:56:46.763804Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class MentalHealthDataset(Dataset):\n    def __init__(self, texts, targets, tokenizer, max_len):\n        self.texts = texts\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            truncation=True,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'targets': torch.tensor(self.targets[idx], dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T08:50:29.369281Z","iopub.execute_input":"2025-02-16T08:50:29.369605Z","iopub.status.idle":"2025-02-16T08:50:29.375220Z","shell.execute_reply.started":"2025-02-16T08:50:29.369578Z","shell.execute_reply":"2025-02-16T08:50:29.374357Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Model Architecture\nclass DebertaClassifier(nn.Module):\n    def __init__(self, model_name, num_classes):\n        super().__init__()\n        self.deberta = DebertaV2Model.from_pretrained(model_name)\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(self.deberta.config.hidden_size, num_classes)\n        nn.init.xavier_normal_(self.classifier.weight)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]\n        return self.classifier(self.dropout(pooled_output))\n\nclass RobertaClassifier(nn.Module):\n    def __init__(self, model_name, num_classes):\n        super().__init__()\n        self.roberta = RobertaModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(self.roberta.config.hidden_size, num_classes)\n        nn.init.xavier_normal_(self.classifier.weight)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]\n        return self.classifier(self.dropout(pooled_output))","metadata":{"_uuid":"37bd426b-46f9-4999-8c42-e32019013135","_cell_guid":"ae5cbbd4-31df-47f9-8f97-d2cd4f3e095b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-16T08:50:45.626617Z","iopub.execute_input":"2025-02-16T08:50:45.626907Z","iopub.status.idle":"2025-02-16T08:50:45.633590Z","shell.execute_reply.started":"2025-02-16T08:50:45.626886Z","shell.execute_reply":"2025-02-16T08:50:45.632551Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Trainer Class\nclass Trainer:\n    def __init__(self, model, model_cfg, train_loader, val_loader, class_weights):\n        self.model = nn.DataParallel(model).to(Config.device) if torch.cuda.device_count() > 1 else model.to(Config.device)\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.optimizer = AdamW(self.model.parameters(), lr=model_cfg['lr'])\n        self.scheduler = get_linear_schedule_with_warmup(\n            self.optimizer,\n            num_warmup_steps=0,\n            num_training_steps=len(train_loader) * Config.epochs\n        )\n        self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n        self.scaler = torch.cuda.amp.GradScaler()\n\n    def train_epoch(self):\n        self.model.train()\n        total_loss = 0\n        progress_bar = tqdm(self.train_loader, desc='Training')\n        for batch in progress_bar:\n            inputs = {k: v.to(Config.device) for k, v in batch.items() if k != 'targets'}\n            targets = batch['targets'].to(Config.device)\n            \n            with torch.cuda.amp.autocast():\n                outputs = self.model(**inputs)\n                loss = self.criterion(outputs, targets)\n            \n            self.scaler.scale(loss).backward()\n            self.scaler.step(self.optimizer)\n            self.scaler.update()\n            self.optimizer.zero_grad()\n            self.scheduler.step()\n            \n            total_loss += loss.item()\n            progress_bar.set_postfix({'loss': total_loss/(len(progress_bar)+1)})\n        return total_loss / len(self.train_loader)\n\n    def validate(self):\n        self.model.eval()\n        val_loss = 0\n        all_preds = []\n        all_targets = []\n        with torch.no_grad():\n            for batch in tqdm(self.val_loader, desc='Validating'):\n                inputs = {k: v.to(Config.device) for k, v in batch.items() if k != 'targets'}\n                targets = batch['targets'].to(Config.device)\n                outputs = self.model(**inputs)\n                loss = self.criterion(outputs, targets)\n                val_loss += loss.item()\n                all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                all_targets.extend(targets.cpu().numpy())\n        \n        f1 = f1_score(all_targets, all_preds, average='macro')\n        print(classification_report(all_targets, all_preds))\n        return val_loss / len(self.val_loader), f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T08:53:07.369238Z","iopub.execute_input":"2025-02-16T08:53:07.369644Z","iopub.status.idle":"2025-02-16T08:53:07.379627Z","shell.execute_reply.started":"2025-02-16T08:53:07.369613Z","shell.execute_reply":"2025-02-16T08:53:07.378634Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def train_model(model_type):\n    # Load data\n    df = pd.read_csv('/kaggle/input/gods-dataset/Train.csv')\n    df['text'] = df['title'] + ' ' + df['content'].fillna('')\n    class_names = df['target'].unique()\n    label2id = {cls: i for i, cls in enumerate(class_names)}\n    df['label'] = df['target'].map(label2id)\n    print(\"Balancing dataset with augmented samples for classes 0 and 4...\")\n    balanced_df = balance_dataset(df, augment_classes=[0, 4])\n    print(f\"Original class distribution: {df['label'].value_counts()}\")\n    print(f\"Balanced class distribution: {balanced_df['label'].value_counts()}\")\n    \n    \n    # Split data\n    train_df, val_df = train_test_split(balanced_df, test_size=0.2, stratify=df['label'], random_state=42)\n    \n    # Model setup\n    model_cfg = Config.models[model_type]\n    tokenizer = DebertaV2Tokenizer.from_pretrained(model_cfg['name']) if 'deberta' in model_type else RobertaTokenizer.from_pretrained(model_cfg['name'])\n    \n    # Datasets\n    train_dataset = MentalHealthDataset(\n        train_df['text'].values,\n        train_df['label'].values,\n        tokenizer,\n        model_cfg['max_len']\n    )\n    val_dataset = MentalHealthDataset(\n        val_df['text'].values,\n        val_df['label'].values,\n        tokenizer,\n        model_cfg['max_len']\n    )\n    \n    # DataLoaders\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=model_cfg['batch_size'],\n        shuffle=True,\n        num_workers=Config.num_workers\n    )\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=model_cfg['batch_size']*2,\n        num_workers=Config.num_workers\n    )\n    \n    # Model initialization\n    if 'deberta' in model_type:\n        model = DebertaClassifier(model_cfg['name'], Config.num_classes)\n    else:\n        model = RobertaClassifier(model_cfg['name'], Config.num_classes)\n    \n    # Class weights\n    class_counts = Counter(train_df['label'])\n    class_weights = torch.tensor([\n        1.0 / class_counts[i] for i in sorted(class_counts.keys())\n    ], dtype=torch.float32).to(Config.device)\n    \n    # Training\n    trainer = Trainer(model, model_cfg, train_loader, val_loader, class_weights)\n    best_f1 = 0\n    for epoch in range(Config.epochs):\n        print(f'\\nEpoch {epoch+1}/{Config.epochs}')\n        trainer.train_epoch()\n        _, val_f1 = trainer.validate()\n        \n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            torch.save(trainer.model.module.state_dict() if isinstance(trainer.model, nn.DataParallel) \n                      else trainer.model.state_dict(), f'best_{model_type}.pth')\n            print(f'Best model saved for {model_type} with F1: {best_f1:.4f}')","metadata":{"_uuid":"063f637a-aa7c-4e5f-a728-f2a198b96334","_cell_guid":"8f0c8200-8dd5-417b-b766-62493ee33162","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def voting_submission():\n    test_df = pd.read_csv('/kaggle/input/gods-dataset/Test.csv')\n    test_df['text'] = test_df['title'] + ' ' + test_df['content'].fillna('')\n    \n    # Load label mappings\n    train_df = pd.read_csv('/kaggle/input/gods-dataset/Train.csv')\n    class_names = train_df['target'].unique()\n    label2id = {cls: i for i, cls in enumerate(class_names)}\n    id2label = {v: k for k, v in label2id.items()}\n    \n    # Initialize models\n    models = []\n    for model_type in ['deberta', 'roberta-base', 'roberta-large']:\n        model_cfg = Config.models[model_type]\n        tokenizer = DebertaV2Tokenizer.from_pretrained(model_cfg['name']) if 'deberta' in model_type else RobertaTokenizer.from_pretrained(model_cfg['name'])\n        \n        # Create dataset\n        test_dataset = MentalHealthDataset(\n            test_df['text'].values,\n            np.zeros(len(test_df)),  # Dummy targets\n            tokenizer,\n            model_cfg['max_len']\n        )\n        test_loader = DataLoader(\n            test_dataset,\n            batch_size=model_cfg['batch_size']*2,\n            num_workers=Config.num_workers\n        )\n        \n        # Load model\n        if 'deberta' in model_type:\n            model = DebertaClassifier(model_cfg['name'], Config.num_classes)\n        else:\n            model = RobertaClassifier(model_cfg['name'], Config.num_classes)\n        \n        model.load_state_dict(torch.load(f'best_{model_type}.pth', map_location=Config.device))\n        model.to(Config.device)\n        model.eval()\n        \n        # Predict\n        preds = []\n        with torch.no_grad():\n            for batch in tqdm(test_loader, desc=f'Predicting with {model_type}'):\n                inputs = {k: v.to(Config.device) for k, v in batch.items() if k != 'targets'}\n                outputs = model(**inputs)\n                preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n        \n        models.append(preds)\n        del model\n        torch.cuda.empty_cache()\n    \n    # Voting\n    final_preds = []\n    for i in range(len(test_df)):\n        votes = [models[0][i], models[1][i], models[2][i]]\n        final_preds.append(max(set(votes), key=votes.count))\n    \n    submission = pd.DataFrame({\n        'id': test_df['id'],\n        'target': [id2label[p] for p in final_preds]\n    })\n    submission.to_csv('voted_submission.csv', index=False)\n    print(\"Voted submission saved!\")","metadata":{"_uuid":"d044ce0b-1e0a-4f8c-81e7-06c8439e41c6","_cell_guid":"1b944705-fa34-4516-b80b-4441bf31f773","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-16T09:00:20.954164Z","iopub.execute_input":"2025-02-16T09:00:20.954522Z","iopub.status.idle":"2025-02-16T09:00:20.963910Z","shell.execute_reply.started":"2025-02-16T09:00:20.954491Z","shell.execute_reply":"2025-02-16T09:00:20.962843Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"if __name__ == '__main__':\n    # Train all models\n    for model_type in Config.models.keys():\n        print(f'\\n{\"=\"*40}\\nTraining {model_type}\\n{\"=\"*40}')\n        train_model(model_type)\n    \n    # Generate voted predictions\n    voting_submission()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T09:00:37.647831Z","iopub.execute_input":"2025-02-16T09:00:37.648103Z","iopub.status.idle":"2025-02-16T09:00:42.490094Z","shell.execute_reply.started":"2025-02-16T09:00:37.648081Z","shell.execute_reply":"2025-02-16T09:00:42.488650Z"}},"outputs":[{"name":"stdout","text":"\n========================================\nTraining deberta\n========================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e83901e649d54a7585c94c73d4600d5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c76596737be242d8ac55a3ec94351853"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f661b1a4ef9f42ba92816b16ad384cf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc18c4f3c66647e59a63d6e0ecb7e6eb"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-5b96cab32668>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n{\"=\"*40}\\nTraining {model_type}\\n{\"=\"*40}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Generate voted predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-249c077c1d41>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_type)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Model initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'deberta'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDebertaClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-8a61761e3933>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, num_classes)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeberta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDebertaV2Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3852\u001b[0m                             \u001b[0;31m# This repo has no safetensors file of any kind, we switch to PyTorch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3853\u001b[0m                             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_variant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3854\u001b[0;31m                             resolved_archive_file = cached_file(\n\u001b[0m\u001b[1;32m   3855\u001b[0m                                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3856\u001b[0m                             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         )\n\u001b[1;32m    859\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mWeakFileLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         _download_to_tmp_and_move(\n\u001b[0m\u001b[1;32m   1010\u001b[0m             \u001b[0mincomplete_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".incomplete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mdestination_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0m_check_disk_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m         http_get(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mnew_resume_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOWNLOAD_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     def _raw_read(\n","\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0;31m# clip the read to the \"end of response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":13},{"cell_type":"markdown","source":"# Thank You ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}